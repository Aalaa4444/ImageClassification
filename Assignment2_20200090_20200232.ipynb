{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3DkgMCTIlFe",
        "outputId": "15c73932-e429-4519-e516-eb872c93328d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(12665, 784)\n",
            "(2115, 784)\n"
          ]
        }
      ],
      "source": [
        "#ID : 20200090 + 20200232\n",
        "#\n",
        "# S: 5\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train=X_train.astype('float64')\n",
        "X_test=X_test.astype('float64')\n",
        "\n",
        "train_mask = np.logical_or(y_train == 0, y_train == 1)\n",
        "test_mask = np.logical_or(y_test == 0, y_test == 1)\n",
        "X_train, y_train = X_train[train_mask], y_train[train_mask]\n",
        "X_test, y_test = X_test[test_mask], y_test[test_mask]\n",
        "\n",
        "shuffled_indices = np.random.permutation(len(X_train))\n",
        "X_train = X_train[shuffled_indices]\n",
        "y_train = y_train[shuffled_indices]\n",
        "\n",
        "X_imgtrain=X_train\n",
        "X_imgtest=X_test\n",
        "\"\"\"\n",
        "#scale\n",
        "X_train = X_train/255 \n",
        "X_test = X_test/255\n",
        "\"\"\"\n",
        "std=np.std(X_train, axis=0)\n",
        "std=np.where(std==0,1,std)\n",
        "X_train=(X_train - np.mean(X_train,axis=0))/std\n",
        "\n",
        "std1=np.std(X_test, axis=0)\n",
        "std1=np.where(std1==0,1,std1)\n",
        "X_test=(X_test - np.mean(X_test,axis=0))/std1\n",
        "\n",
        "X_train = np.reshape(X_train, (-1, 784))\n",
        "X_test = np.reshape(X_test, (-1, 784))\n",
        "\n",
        "print(X_train.shape)  \n",
        "print(X_test.shape)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "ncpz5_CPIn2X",
        "outputId": "5b6b465d-225c-47ff-9c46-1ab6fb0f97a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label: 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image, label = X_imgtrain[0],y_train[0]\n",
        "plt.imshow(image, cmap='gray')\n",
        "print(\"Label:\",label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UIwbjyRXIsv2"
      },
      "outputs": [],
      "source": [
        "def train_val_split(X_train,y_train,split_ratio =0.8):\n",
        "    np.random.seed(0)\n",
        "    shuffle_indices = np.random.permutation(len(y_train))\n",
        "    X_shuffled = X_train[shuffle_indices]\n",
        "    y_shuffled = y_train[shuffle_indices]\n",
        "    split_index = int(len(y_train) * split_ratio)\n",
        "    # Split the data\n",
        "    X_train = X_shuffled[:split_index]\n",
        "    y_train = y_shuffled[:split_index]\n",
        "    X_val = X_shuffled[split_index:]\n",
        "    y_val = y_shuffled[split_index:]\n",
        "\n",
        "    return X_train, X_val, y_train, y_val\n",
        "\n",
        "\n",
        "X, val_X, y, val_y=train_val_split(X_train,y_train, 0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yM6O21fUPm27"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    #return 1.0 / (1.0 + np.exp(-z)) \n",
        "    res=np.where((-z) > 0, 1.0 / (1.0 + np.exp(-z)), 1.0 / (1.0 + np.exp(-z+ 1e-15)))   \n",
        "    return res\n",
        "def pred(val_X,val_y,w,b):\n",
        "    z=(val_X @ w)+b\n",
        "    prediction = sigmoid(z)     \n",
        "    prediction = [1 if elem > 0.5 else 0 for elem in prediction]         \n",
        "    error=np.sum(prediction !=  val_y)  \n",
        "    score=round(np.mean(prediction ==  val_y)*100,2)\n",
        "    print(\"error\",error)\n",
        "    print(\"score\",score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rFewyeFIKLdN"
      },
      "outputs": [],
      "source": [
        "def logisticRegression_L1(X, y,w,b, num_iter, lr, lambda_val):\n",
        "    tolerance = 1e-8\n",
        "    m, n = X.shape \n",
        "\n",
        "    for i in range(num_iter):\n",
        "        z = X @ w\n",
        "        yp = sigmoid(z)\n",
        "        y = y.reshape((m, 1))\n",
        "        cost = (1 / m) * (-(y.T @ np.log(yp)) - ((1 - y).T @ np.log(1 - yp))) + (lambda_val / m) * np.sum(np.abs(w))\n",
        "        cost = cost.sum(axis=0)\n",
        "        dw = (1 / m) * (X.T @ (yp - y)) + (lambda_val / m) * np.sign(w)\n",
        "        w = w - (dw * lr)\n",
        "        db = np.mean(yp - y) \n",
        "        b = b - (db * lr)\n",
        "        if cost < tolerance:\n",
        "            break\n",
        "\n",
        "    return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "unNXupzSKtOd"
      },
      "outputs": [],
      "source": [
        "def logisticRegression_miniBatch(X, y,w,b, num_iter, lr, batch_size):\n",
        "    tolerance = 1e-8\n",
        "    m, n = X.shape\n",
        "    num_batches = int(np.ceil(m / batch_size))\n",
        "    for i in range(num_iter):\n",
        "        cost = 0\n",
        "        for j in range(num_batches):\n",
        "            batch_start = j * batch_size\n",
        "            batch_end = min(batch_start + batch_size, m)\n",
        "            X_batch = X[batch_start:batch_end, :]\n",
        "            y_batch = (y[batch_start:batch_end]).reshape(-1,1)\n",
        "            z = X_batch @ w\n",
        "            yp = sigmoid(z)\n",
        "            cost += (1 / m) * (-(y_batch.T @ np.log(yp)) - ((1 - y_batch).T @ np.log(1 - yp)))\n",
        "            dw = (1 / m) * (X_batch.T @ (yp - y_batch))\n",
        "            w = w - (dw * lr)\n",
        "            db = np.mean(yp - y_batch)\n",
        "            b = b - (db * lr)\n",
        "        if cost < tolerance:\n",
        "            break\n",
        "    return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RplSFkcgLClC"
      },
      "outputs": [],
      "source": [
        "def logisticRegression_RMSprop(X, y,w,b, num_iter, lr, b1, epsilon= 1e-8):\n",
        "    tolerance = 1e-8\n",
        "    m, n = X.shape \n",
        "    vdw = np.zeros((n,1))\n",
        "    vdb = 0\n",
        "    t = 0\n",
        "    \n",
        "    for i in range(num_iter):\n",
        "        t += 1\n",
        "        z = X @ w\n",
        "        yp = sigmoid(z) \n",
        "        y = y.reshape((m, 1))        \n",
        "        cost= (1 / m) *( -(y.T @ np.log(yp)) - ((1 - y).T @ np.log(1 - yp)) ) \n",
        "        cost = cost.sum(axis=0)\n",
        "        dw = (1 / m) * (X.T @ (yp - y))\n",
        "        vdw = (b1 * vdw + (1 - b1) * np.square(dw))/ (1 - b1 ** t)  #unbiased\n",
        "        w = w - (lr * dw / (np.sqrt(vdw) + epsilon))\n",
        "        \n",
        "        db = np.mean(yp - y)\n",
        "        vdb = (b1 * vdb + (1 - b1) * np.square(db))/ (1 - b1 ** t)  #unbiased\n",
        "        b = b - (lr * db / (np.sqrt(vdb) + epsilon))\n",
        "\n",
        "        if cost < tolerance: break\n",
        "        \n",
        "    return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RQUsWakLLE5K"
      },
      "outputs": [],
      "source": [
        "def logisticRegression_Adam(X, y,w,b, num_iter, lr, b1, b2, epsilon= 1e-8):\n",
        "    tolerance = 1e-8\n",
        "    m, n = X.shape \n",
        "    vdw_m = np.zeros((n,1))      #momentum for w\n",
        "    vdw_rms = np.zeros((n,1))    #RMSprop  for w\n",
        "\n",
        "    vdb_m = 0                    #momentum for b\n",
        "    vdb_rms = 0                  #RMSprop  for b\n",
        "    t = 0\n",
        "    \n",
        "    for i in range(num_iter):\n",
        "        t += 1\n",
        "        z = (X @ w)+b\n",
        "        yp = sigmoid(z)\n",
        "        y = y.reshape((m, 1))        \n",
        "        cost= (1 / m) *( -(y.T @ np.log(yp)) - ((1 - y).T @ np.log(1 - yp)) ) \n",
        "        cost = cost.sum(axis=0)\n",
        "        dw = (1 / m) * (X.T @ (yp - y))\n",
        "        vdw_m = (b1 * vdw_m + (1 - b1) * dw)/ (1 - b1 ** t)                     #momentum_unbiased       \n",
        "        vdw_rms = (b2 * vdb_rms + (1 - b2) * np.square(dw))/ (1 - b2 ** t)      #RMSprop_unbiased\n",
        "        w = w - (lr * vdw_m / (np.sqrt(vdw_rms) + epsilon))\n",
        "\n",
        "        db = np.mean(yp - y)\n",
        "        vdb_m = (b1 * vdb_m + (1 - b1) * db)/ (1 - b1 ** t)                     #momentum_unbiased  \n",
        "        vdb_rms = (b2 * vdb_m + (1 - b2) * np.square(db))/ (1 - b2 ** t)        #RMSprop_unbiased\n",
        "        b = b - (lr * vdb_m / (np.sqrt(vdb_rms) + epsilon))\n",
        "        \n",
        "        \n",
        "        if cost < tolerance: break\n",
        "        \n",
        "    return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "w = np.random.uniform(size=(X.shape[1],1), low=-0.2, high=0.1)\n",
        "b = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSFMCN-PwV-H",
        "outputId": "fd1cbc7b-a13a-4cd0-f595-670a0ea5b3a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L1_reg with lambda_val=1\n",
            "error 4\n",
            "score 99.84\n",
            "L1_reg with lambda_val=0.1\n",
            "error 4\n",
            "score 99.84\n",
            "MiniBatch with batch_size=5000\n",
            "error 4\n",
            "score 99.84\n",
            "MiniBatch with batch_size=1000\n",
            "error 8\n",
            "score 99.68\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_5436/1850094203.py:13: RuntimeWarning: divide by zero encountered in log\n",
            "  cost= (1 / m) *( -(y.T @ np.log(yp)) - ((1 - y).T @ np.log(1 - yp)) )\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_5436/1850094203.py:13: RuntimeWarning: invalid value encountered in matmul\n",
            "  cost= (1 / m) *( -(y.T @ np.log(yp)) - ((1 - y).T @ np.log(1 - yp)) )\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_5436/1876696833.py:16: RuntimeWarning: divide by zero encountered in log\n",
            "  cost= (1 / m) *( -(y.T @ np.log(yp)) - ((1 - y).T @ np.log(1 - yp)) )\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_5436/1876696833.py:16: RuntimeWarning: invalid value encountered in matmul\n",
            "  cost= (1 / m) *( -(y.T @ np.log(yp)) - ((1 - y).T @ np.log(1 - yp)) )\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_5436/950542085.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  res=np.where((-z) > 0, 1.0 / (1.0 + np.exp(-z)), 1.0 / (1.0 + np.exp(-z+ 1e-15)))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSprop\n",
            "error 32\n",
            "score 98.74\n",
            "Adam\n",
            "error 6\n",
            "score 99.76\n"
          ]
        }
      ],
      "source": [
        "w1_L1,b1_L1 = logisticRegression_L1(X, y,w,b, num_iter=1000, lr=0.1, lambda_val=1)\n",
        "w2_L1,b2_L1 = logisticRegression_L1(X, y,w,b, num_iter=1000, lr=0.1, lambda_val=0.1)\n",
        "print(\"L1_reg with lambda_val=1\")\n",
        "pred(val_X,val_y,w1_L1,b1_L1)\n",
        "print(\"L1_reg with lambda_val=0.1\")\n",
        "pred(val_X,val_y,w2_L1,b2_L1)\n",
        "\n",
        "w1_miniBatch,b1_miniBatch = logisticRegression_miniBatch(X, y,w,b, num_iter=1000, lr=0.1, batch_size=5000)\n",
        "w2_miniBatch,b2_miniBatch = logisticRegression_miniBatch(X, y,w,b, num_iter=1000, lr=0.1, batch_size=1000)\n",
        "print(\"MiniBatch with batch_size=5000\")\n",
        "pred(val_X,val_y,w1_miniBatch,b1_miniBatch)\n",
        "print(\"MiniBatch with batch_size=1000\")\n",
        "pred(val_X,val_y,w2_miniBatch,b2_miniBatch)\n",
        "\n",
        "w_rms,b_rms = logisticRegression_RMSprop(X, y,w,b, num_iter=1000, lr=0.1, b1=0.99)\n",
        "w_adam,b_adam = logisticRegression_Adam(X, y,w,b, num_iter=1000, lr=0.1, b1=0.9, b2=0.99)\n",
        "print(\"RMSprop\")\n",
        "pred(val_X,val_y,w_rms,b_rms)\n",
        "print(\"Adam\")\n",
        "pred(val_X,val_y,w_adam,b_adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi8xGZAaEk46",
        "outputId": "118ebd0c-d288-4cb4-cf1b-e522e1611be4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L1_reg with lambda_val=1\n",
            "error 0\n",
            "score 100.0\n",
            "L1_reg with lambda_val=0.1\n",
            "error 0\n",
            "score 100.0\n",
            "MiniBatch with batch_size=5000\n",
            "error 1\n",
            "score 99.95\n",
            "MiniBatch with batch_size=1000\n",
            "error 2\n",
            "score 99.91\n",
            "RMSprop\n",
            "error 19\n",
            "score 99.1\n",
            "Adam\n",
            "error 3\n",
            "score 99.86\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_5436/950542085.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  res=np.where((-z) > 0, 1.0 / (1.0 + np.exp(-z)), 1.0 / (1.0 + np.exp(-z+ 1e-15)))\n"
          ]
        }
      ],
      "source": [
        "# test data\n",
        "print(\"L1_reg with lambda_val=1\")\n",
        "pred(X_test,y_test,w1_L1,b1_L1)\n",
        "print(\"L1_reg with lambda_val=0.1\")\n",
        "pred(X_test,y_test,w2_L1,b2_L1)\n",
        "\n",
        "print(\"MiniBatch with batch_size=5000\")\n",
        "pred(X_test,y_test,w1_miniBatch,b1_miniBatch)\n",
        "print(\"MiniBatch with batch_size=1000\")\n",
        "pred(X_test,y_test,w2_miniBatch,b2_miniBatch)\n",
        "\n",
        "print(\"RMSprop\")\n",
        "pred(X_test,y_test,w_rms,b_rms)\n",
        "print(\"Adam\")\n",
        "pred(X_test,y_test,w_adam,b_adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SPflvik3Kb2",
        "outputId": "7f34d4e6-f2b0-447b-f926-8d4622f79f47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 0.986\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "clf = SGDClassifier(loss='log', penalty='l1', alpha=0.1, random_state=42)\n",
        "clf.fit(X, y)\n",
        "accuracy = clf.score(val_X, val_y)\n",
        "print(f\"Validation accuracy: {accuracy:.3f}\")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lambdas = [1, 0.1]\n",
        "for lambda_val in lambdas:\n",
        "    lr = LogisticRegression(penalty='l1', C=1/lambda_val, solver='saga', max_iter=10000)\n",
        "    lr.fit(X, y)\n",
        "    val_score = lr.score(val_X, val_y)\n",
        "    print(f'Lambda: {lambda_val}, Validation Score: {val_score}, '\n",
        "          f'Number of Non-Zero Coefficients: {np.count_nonzero(lr.coef_)}')\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeymFAbU8q1c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
